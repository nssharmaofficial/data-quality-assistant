{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI-Powered Data Quality Management Demo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('../src')\n",
        "\n",
        "from data_quality_assistant.assistant import DataQualityAssistant\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:data_quality_assistant.assistant:Database setup complete. Data shape: (13152, 19)\n",
            "INFO:data_quality_assistant.assistant:Assistant initialized with data from: ../data/data.xlsx\n"
          ]
        }
      ],
      "source": [
        "data_path = \"../data/data.xlsx\"\n",
        "assistant = DataQualityAssistant(data_path=data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùì Question: How many rows are in the data?\n",
            "ü§ñ Answer: The data table contains a total of 13,152 rows. This indicates a substantial dataset that can be utilized for various analyses and insights. \n",
            "\n",
            "Key Insights:\n",
            "1. **Data Volume**: With over 13,000 entries, the dataset is likely to provide a robust basis for statistical analysis, trend identification, and decision-making processes.\n",
            "2. **Potential for Insights**: Depending on the nature of the data, this volume can help in uncovering patterns, correlations, and anomalies that could be valuable for business strategies.\n",
            "\n",
            "Data Quality Observations:\n",
            "- It is important to ensure that the data is clean and free from duplicates or errors, as these can skew results and lead to incorrect conclusions.\n",
            "- Consider performing a data quality assessment to check for missing values or inconsistencies that may affect analysis.\n",
            "\n",
            "Actionable Recommendations:\n",
            "- If not already done, implement regular data audits to maintain data integrity.\n",
            "- Explore the dataset further to understand its structure and the types of analyses that can be performed, which could enhance decision-making and operational efficiency.\n",
            "üíª SQL Query: SELECT COUNT(*) FROM data_table;\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "question = \"How many rows are in the data?\"\n",
        "result = assistant.ask_question(question)\n",
        "\n",
        "print(f\"‚ùì Question: {result.user_question}\")\n",
        "print(f\"ü§ñ Answer: {result.final_answer}\")\n",
        "print(f\"üíª SQL Query: {result.sql_query}\")\n",
        "if result.error_message:\n",
        "    print(f\"‚ùå Error: {result.error_message}\")\n",
        "print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùì Question: How many missing values are in each column?\n",
            "ü§ñ Answer: Based on the SQL query results, we have identified the number of missing values in each column of the dataset. Here are the findings:\n",
            "\n",
            "- **Unnamed: 0**: 0 missing values\n",
            "- **Authorization Group**: 0 missing values\n",
            "- **Bus. Transac. Type**: 0 missing values\n",
            "- **Calculate Tax**: 12,838 missing values\n",
            "- **Cash Flow-Relevant Doc.**: 0 missing values\n",
            "- **Cleared Item**: 0 missing values\n",
            "- **Clearing Date**: 8,852 missing values\n",
            "- **Clearing Entry Date**: 8,852 missing values\n",
            "- **Clearing Fiscal Year**: 8,852 missing values\n",
            "- **Country Key**: 0 missing values\n",
            "- **Currency**: 0 missing values\n",
            "- **Debit/Credit ind**: 0 missing values\n",
            "- **Transaction Value**: 0 missing values\n",
            "- **Document Is Back-Posted**: 8,030 missing values\n",
            "- **Exchange rate**: 13,102 missing values\n",
            "- **Fiscal Year.1**: 8,068 missing values\n",
            "- **Fiscal Year.2**: 0 missing values\n",
            "- **Posting period.1**: 0 missing values\n",
            "- **Ref. Doc. Line Item**: 0 missing values\n",
            "\n",
            "### Key Insights:\n",
            "1. **High Missing Values**: The columns \"Calculate Tax\", \"Clearing Date\", \"Clearing Entry Date\", \"Clearing Fiscal Year\", \"Document Is Back-Posted\", and \"Exchange rate\" have significant missing values, which could impact data analysis and decision-making.\n",
            "2. **Data Completeness**: Other columns show no missing values, indicating that the dataset is relatively complete in those areas.\n",
            "\n",
            "### Recommendations:\n",
            "- **Data Cleaning**: It is crucial to address the high number of missing values in the identified columns. Consider strategies such as data imputation, removal of records, or further investigation into why these values are missing.\n",
            "- **Impact Assessment**: Evaluate how the missing values in critical columns like \"Calculate Tax\" and \"Exchange rate\" may affect financial reporting and compliance.\n",
            "- **Regular Monitoring**: Implement a process for regular monitoring of data quality to ensure that missing values are addressed promptly in future data entries.\n",
            "üíª SQL Query: SELECT\n",
            "    SUM(CASE WHEN \"Unnamed: 0\" IS NULL THEN 1 ELSE 0 END) AS \"Unnamed: 0\",\n",
            "    SUM(CASE WHEN \"Authorization Group\" IS NULL THEN 1 ELSE 0 END) AS \"Authorization Group\",\n",
            "    SUM(CASE WHEN \"Bus. Transac. Type\" IS NULL THEN 1 ELSE 0 END) AS \"Bus. Transac. Type\",\n",
            "    SUM(CASE WHEN \"Calculate Tax\" IS NULL THEN 1 ELSE 0 END) AS \"Calculate Tax\",\n",
            "    SUM(CASE WHEN \"Cash Flow-Relevant Doc.\" IS NULL THEN 1 ELSE 0 END) AS \"Cash Flow-Relevant Doc.\",\n",
            "    SUM(CASE WHEN \"Cleared Item\" IS NULL THEN 1 ELSE 0 END) AS \"Cleared Item\",\n",
            "    SUM(CASE WHEN \"Clearing Date\" IS NULL THEN 1 ELSE 0 END) AS \"Clearing Date\",\n",
            "    SUM(CASE WHEN \"Clearing Entry Date\" IS NULL THEN 1 ELSE 0 END) AS \"Clearing Entry Date\",\n",
            "    SUM(CASE WHEN \"Clearing Fiscal Year\" IS NULL THEN 1 ELSE 0 END) AS \"Clearing Fiscal Year\",\n",
            "    SUM(CASE WHEN \"Country Key\" IS NULL THEN 1 ELSE 0 END) AS \"Country Key\",\n",
            "    SUM(CASE WHEN \"Currency\" IS NULL THEN 1 ELSE 0 END) AS \"Currency\",\n",
            "    SUM(CASE WHEN \"Debit/Credit ind\" IS NULL THEN 1 ELSE 0 END) AS \"Debit/Credit ind\",\n",
            "    SUM(CASE WHEN \"Transaction Value\" IS NULL THEN 1 ELSE 0 END) AS \"Transaction Value\",\n",
            "    SUM(CASE WHEN \"Document Is Back-Posted\" IS NULL THEN 1 ELSE 0 END) AS \"Document Is Back-Posted\",\n",
            "    SUM(CASE WHEN \"Exchange rate\" IS NULL THEN 1 ELSE 0 END) AS \"Exchange rate\",\n",
            "    SUM(CASE WHEN \"Fiscal Year.1\" IS NULL THEN 1 ELSE 0 END) AS \"Fiscal Year.1\",\n",
            "    SUM(CASE WHEN \"Fiscal Year.2\" IS NULL THEN 1 ELSE 0 END) AS \"Fiscal Year.2\",\n",
            "    SUM(CASE WHEN \"Posting period.1\" IS NULL THEN 1 ELSE 0 END) AS \"Posting period.1\",\n",
            "    SUM(CASE WHEN \"Ref. Doc. Line Item\" IS NULL THEN 1 ELSE 0 END) AS \"Ref. Doc. Line Item\"\n",
            "FROM data_table;\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "question = \"How many missing values are in each column?\"\n",
        "result = assistant.ask_question(question)\n",
        "\n",
        "print(f\"‚ùì Question: {result.user_question}\")\n",
        "print(f\"ü§ñ Answer: {result.final_answer}\")\n",
        "print(f\"üíª SQL Query: {result.sql_query}\")\n",
        "if result.error_message:\n",
        "    print(f\"‚ùå Error: {result.error_message}\")\n",
        "print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùì Question: Are there any duplicate records in the data?\n",
            "ü§ñ Answer: The SQL query you attempted to run to check for duplicate records in the data table resulted in a syntax error due to the use of '*' in the COUNT(DISTINCT *) function. In SQL, you need to specify a column name for the DISTINCT clause. \n",
            "\n",
            "To accurately check for duplicate records, you can modify your query to specify the columns you want to check for duplicates. For example, if you want to check for duplicates based on all columns, you can use a combination of GROUP BY and HAVING clauses:\n",
            "\n",
            "```sql\n",
            "SELECT COUNT(*) - COUNT(DISTINCT column_name) AS duplicate_count \n",
            "FROM data_table;\n",
            "```\n",
            "\n",
            "Alternatively, if you want to find duplicates based on specific columns, you can use:\n",
            "\n",
            "```sql\n",
            "SELECT column1, column2, COUNT(*) \n",
            "FROM data_table \n",
            "GROUP BY column1, column2 \n",
            "HAVING COUNT(*) > 1;\n",
            "```\n",
            "\n",
            "This will give you a count of how many times each combination of column1 and column2 appears in the table, allowing you to identify duplicates. \n",
            "\n",
            "**Key Insights:**\n",
            "- Duplicates can lead to data quality issues, affecting analysis and reporting.\n",
            "- Identifying duplicates is crucial for maintaining the integrity of your data.\n",
            "\n",
            "**Actionable Recommendations:**\n",
            "1. Revise your SQL query to specify the columns for checking duplicates.\n",
            "2. Run the modified query to identify any duplicate records.\n",
            "3. If duplicates are found, consider implementing data cleaning processes to remove or consolidate them.\n",
            "üíª SQL Query: SELECT COUNT(*) - COUNT(DISTINCT *) AS duplicate_count FROM data_table;\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Question 3: Duplicate detection\n",
        "question = \"Are there any duplicate records in the data?\"\n",
        "result = assistant.ask_question(question)\n",
        "\n",
        "print(f\"‚ùì Question: {result.user_question}\")\n",
        "print(f\"ü§ñ Answer: {result.final_answer}\")\n",
        "print(f\"üíª SQL Query: {result.sql_query}\")\n",
        "if result.error_message:\n",
        "    print(f\"‚ùå Error: {result.error_message}\")\n",
        "print(\"-\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "AI Data Quality Solution",
      "language": "python",
      "name": "ai-data-quality"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
